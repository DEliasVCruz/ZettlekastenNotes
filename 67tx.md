# lang.py.module.pandas.conditional_replacement

Replace values in a column according to some condition

## Synopsis

```py
  df[<column>].where(<condition>, <replacement-if-false>)
  df[<column>].mask(<condition>, <replacement-if-true>)
  df[<column>] = np.where(<condition>, <replacement-if-true>, <replacement-if-false>)
  df[<column>] = np.select(<conditions-array>, <results-array>, default=<default-value>)
```

## Overview

You can **replace or add values** in columns of your dataframe **based on an
specified condition**

For that you can **either** of **three methods**:

- `where()`: **Replace** values **where** the **condition is not met**
- `mask()`: **Replace** values **where** the **condition is met**
- `np.where()`: **Replaces** values with **one value if** the **condition is met
  and another if not**

This is a nice way to **vectorize** your workflows, so that you don't
have to rely on for loops or [apply](./slpd.md) 

## Cookbook

### Replace a value based on a failed conditional

You can use the `where()` method to **replace values where** the specified
**condition is not met**

- `cond`: An specified **logical condition** (An **array of boolean values** )
- `other`: The **value to replace for** if the condition is not met
- `try_cast`: If the replace value is not of the same type then set this to `False`

It **does not perform mutation**, instead it returns a new `series` or
dataframe object

```py
  df['django-score'] = df['django-score'].where(cond=df['django-score'] >= 80, other=0.0)
```

### Replace a value based on a successful conditional

You can use the `mask()` method to **replace values where** the specified
**condition is met**

- `cond`: An specified **logical condition** (An **array of boolean values** )
- `other`: The **value to replace for** if the condition is met
- `try_cast`: If the replace value is not of the same type then set this to `False`

It **does not perform mutation**, instead it returns a new `series` or
dataframe object

```py
  df['django-score'] = df['django-score'].mask(cond=df['django-score'] >= 80,
                                               other="Yes", try_cast=False)
```

### Replace a value based on a conditional

You can use the `np.where()` method from the [numpy](./5nfr.md) library to
**replace values** based on **wheter or not a condition is satisfied**

- `cond`: An specified condition to be evaluated
- `x`: Value to be replaced for if the condition is met
- `y`: Value to be replaced for if the condition is not met

```py
  df['django-score'] = np.where(df['django-score'] >= 80, "Yes", 0)
```

### Replace the use of `apply` with a vectorize conditional

Consider the case where you want to do some conditional application
to a `dataframe` column.

You could use the standard `apply` method like so:

```py
docdef set_lead_status(row):
  if row['current_status'] == 'None':
    return row['status_at_time_of_lead']
  else:
    return row['current_status']

df['status'] = df.apply(set_lead_status, axis=1)
```

This is fine but depending on how big is your data this could
take an alarming amount of seconds

A better solution would be using [vectorized](./1c2p.md) 
operations, with the `where` method this can be done 
easily

```py
df['status'] = np.where(df['current_status'].values == 'None', 
                        df['status_at_time_of_lead'].values, 
                        df['current_status'].values)
```

### Multiple conditional replacements

As you start to make more complex replacements you may
find yourself using many nested `where` conditions to
achieve your goal

While this is certainly possible, it becomes very
hard to maintain and extend, similar to what happens 
in `excel` when you are doing, multiple if statements

Given the following complex `if stament` base function:

```py
list1 = ['LEAD-3 Flame No Contact', 'LEAD-Campaign', 'LEAD-Claim', 'LEAD-Contact Program', 
         'LEAD-General Pool', 'LEAD-No Contact', 'LEAD-Nurture', 'LEAD-Unqualified', 'PROSPECT-LOST']

list2 = ['- None -', 'CLIENT-Closed-Sold', 'CLIENT-Handoff', 'CLIENT-Implementation', 'CLIENT-Implementation (EMR)',
         'CLIENT-Live', 'CLIENT-Partner', 'CLIENT-Referring Consultant', 'CLIENT-Transferred', 'LEAD-Engaged', 
         'LEAD-Long-Term Opportunity', 'PROSPECT-CURRENT', 'PROSPECT-LONG TERM', 'PROSPECT-NO DECISION']

# apply version
def lead_category(row):
    if row['Original Record: Date Created'] == row['Date Created']:
        return 'New Lead'
    elif row['normalized_status'].startswith('CLI'):
        return 'Client Lead'
    elif row['normalized_status'] in list1:
        return 'MTouch Lead'
    elif row['normalized_status'] in list2:
        return 'EMTouch Lead'
    return 'NA'

df['lead_category'] = df.apply(lead_category, axis=1)
```

That is then converted to the following `where` based
`vectorized` function

```py
df['lead_category'] = np.where(
  df['Original Record: Date Created'].values == df['Date Created'].values, 'New Lead', 
            np.where(df['normalized_status'].str.startswith('CLI').values, 'Client Lead', 
                    np.where(df['normalized_status'].isin(list1).values, 'MTouch Lead', 
                            np.where(df['normalized_status'].isin(list2).values, 'EMTouch Lead', 
                                     'NA') 
                                  )
                         )
                )
```

It's clear that this is unsustainable, a much cleaner
handling of multiple conditions can be achieved with
the [select](./4yz1.md) function

```py
conditions = [
    df['Original Record: Date Created'].values == df['Date Created'].values,
    df['normalized_status'].str.startswith('CLI').values,
    df['normalized_status'].isin(list1).values,
    df['normalized_status'].isin(list2).values
]

choices = [
    'New Lead', 
    'Client Lead', 
    'MTouch Lead',
    'EMTouch Lead'
]


df['lead_category1'] = np.select(conditions, choices, default='NA')  # Order of operations matter!
```

### Replace values with nested conditions

You can effectively use `np.where()` as a **vectorized** `excell if()`

```py
  pub = df['Place of Publication']

  london = pub.str.contains('London')
  oxford = pub.str.contains('Oxford')

  df['Place of Publication'] = np.where(london, 'London',
                                  np.where(oxford, 'Oxford',
                                           pub.str.replace('-', ' ')))
```

### Replace values based on a regular expression

You can use the `extract()` method from the [dataframe str
attribute](./m0jc.md) to replace the values with the matched [regular
expression](./cbw4.md) or `NaN` in case the regex is not matched

```py
  extr = df['Date of Publication'].str.extract(r'^(\d{4})', expand=False)
  df['Date of Publication'] = extr
```

### Speading up the process of conditional replacement

If you are working with [series](./mkgv.md) you can make the process faster
by using the `values` attribute of the series, that way you
will have access to the raw numpy array

This helps since there is not the additional work of having
to get that underlying information since you strip away all the
`series` abstraction like [indexes](./271q.md) 

```py
  df['django-score'] = np.where(df['django-score'].values >= 80, "Yes", 0)
```

## Sources

- A [talk](https://www.youtube.com/watch?v=nxWginnBklU) on how to vectorize conditional in pandas
  - The link to the [documentation](https://gitlab.com/cheevahagadog/talks-demos-n-such/-/blob/master/PyGotham2019/PyGotham-updated.ipynb?plain=0) 
